I"ëY<p>En el siguiente lab voy a instalar y configurar <strong>Terraform</strong> en una m√°quina Windows 11 con <strong>WSL</strong>, haciendo uso de la distribuci√≥n <strong>Ubuntu 22.04 LTS</strong>, pero, el despliegue se puede llevar a cabo desde cualquier m√°quina con Linux. Posteriormente voy a desplegar la siguiente infraestructura en <strong>Azure</strong>:</p>

<ul>
  <li>Un grupo de recursos.</li>
  <li>Una m√°quina virtual con 2vCPU, 4GB de RAM y 30GB HDD con una imagen CentOS (master).</li>
  <li>Dos m√°quinas virtuales con 1vCPU, 2GB de RAM y 30GB HDD con una imagen CentOS (workers).</li>
  <li>Tres IPs p√∫blicas din√°micas.</li>
  <li>Una red virtual.</li>
  <li>Un grupo de seguridad de red (NSG).</li>
</ul>

<h1 id="preparaci√≥n-del-entorno-para-automatizar-el-despliegue">Preparaci√≥n del entorno para automatizar el despliegue</h1>

<p><strong>En primer lugar</strong>, tenemos que instalar Terraform en la m√°quina Linux donde se va automatizar el despliegue. De forma predeterminada, Terraform no est√° incluido en el repositorio est√°ndar de Ubuntu. Debemos instalar los siguientes paquetes:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt-get install curl gnupg2 software-properties-common -y
</code></pre></div></div>
<p>Posteriormente agregamos la clave GPG Terraform y el respositorio:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo curl -fsSL https://apt.releases.hashicorp.com/gpg | apt-key add -
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt-add-repository "deb [arch=$(dpkg --print-architecture)] https://apt.releases.hashicorp.com 
$(lsb_release -cs) main"
</code></pre></div></div>
<p>Por √∫ltimo instalamos Terraform:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt-get install terraform -y
</code></pre></div></div>
<p>Para verificar la instalaci√≥n de Terraform ejecutamos:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform -v
</code></pre></div></div>
<p><img src="/images/terraform-v.png" alt="Ejecuci√≥n de 'terraform -v'" /></p>

<p><strong>En segundo lugar</strong>, tenemos que crear un service principal para conectar el provider azurerm de Terraform con nuestro tenant de Azure. Hacemos uso de <strong>Azure CLI</strong>. Instalamos Azure CLI mediante el siguiente comando:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
</code></pre></div></div>
<p>Para crear un service principal tenemos que conectarnos al tenant de Azure con:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> az login
</code></pre></div></div>

<p>Con el siguiente comando creamos el service principal:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az ad sp create-for-rbac --role="Contributor" --scopes="/subscriptions/529ff35f-375b-xxxx-xxxx-xxxxxxxxxxxx"
</code></pre></div></div>
<p><img src="/images/creacion-service-principal.png" alt="Creaci√≥n de un service principal" /></p>

<h2 id="creaci√≥n-de-estructura-de-directorio-y-archivos-terraform">Creaci√≥n de estructura de directorio y archivos Terraform</h2>

<p>Clonamos el siguiente repositorio en la m√°quina donde vamos automatizar el despliegue de la infraestructura con Terrafrom <code class="language-plaintext highlighter-rouge">https://github.com/ragagu/laboratorios</code></p>

<blockquote>
  <p>Para instalar Git ejecuta el comando <code class="language-plaintext highlighter-rouge">sudo apt install git</code></p>
</blockquote>

<p>Accedemos al directorio laboratorios/terraform/0001 y vemos la estructura de archivos siguientes:</p>

<ul>
  <li>main.tf</li>
  <li>network.tf</li>
  <li>security.tf</li>
  <li>vars.tf</li>
  <li>vm.tf</li>
</ul>

<h3 id="configuraci√≥n-de-archivo-varstf">Configuraci√≥n de archivo vars.tf</h3>

<ul>
  <li>En este fichero declaramos todas las variables.</li>
  <li>Declaramos la localizaci√≥n para ubicar en la regi√≥n donde se van a desplegar los recursos. Para ver las regiones disponibles: az account list-locations</li>
  <li>Declaramos la variable para el nombre de la talla de la m√°quina virtual m√°ster. Para ver las tallas disponibles en la regi√≥n seleccionada: az vm list-sizes ‚Äìlocation westeurope</li>
  <li>Declaramos la variable para el nombre de la talla de las m√°quinas workers. Como las dos VM workers van a ser iguales, solamente va a cambiar el nombre, aplicamos el tipo lists(string) y los nombres de ambas VM en default. En los archivos main.tf, network.tf, security.tf y vm.tf haremos uso de count para configurar estas dos VMs.</li>
</ul>

<p>Si est√°s haciendo uso de una suscripci√≥n de educaci√≥n, est√°n limitadas a un m√°ximo de 4 Cores, este l√≠mite se puede ampliar, pero no es posible hacerlo con este tipo de suscripci√≥n, la soluci√≥n es pasar a una suscripci√≥n de pago por uso.</p>

<p>Contenido archivo vars.tf:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Variable aplicable a todos los recursos

variable "location" {
  type = string
  description = "Regi√≥n donde se crear√°n los recursos de Azure"
  default = "West Europe"
}

# Variable aplicable solo a la VM master

variable "vm_size_master" {
  type = string
  description = "Talla para la VM master"
  default = "Standard_B2s" # 2vCPU, 4GB RAM
}

# Variables aplicables a las VMs worker01 y worker02

variable "vm_size_workers" {
  type = string
  description = "Talla de la VM"
  default = "Standard_B1ms" # 1vCPU, 2GB RAM
}

variable "workers" {
  type = list(string)
  description = "Despliegue de VMs worker01 y worker 02"
  default = ["worker01", "worker02"]
}
</code></pre></div></div>

<h3 id="configuraci√≥n-de-archivo-maintf">Configuraci√≥n de archivo main.tf</h3>

<ul>
  <li>Configuramos el provider del que har√° uso Terraform, en este caso azurerm.</li>
  <li>Incluimos la informaci√≥n del service principal creado.</li>
  <li>Creamos y configuramos un grupo de recursos.</li>
  <li>Creamos y configuramos una cuenta de almacenamiento.</li>
</ul>

<p>Como podemos ver para la configuraci√≥n location se hace llamamiento a la variable var.location, de esta forma se configurar√≠a West Europe, tal y como est√° definido en vars.tf. Tambi√©n observamos que en todos los recursos hay que indicar el nombre del grupo de recursos donde se va a desplegar, como el nombre ya est√° definido en la creaci√≥n del grupo de recursos, el llamamiento al nombre de este en la creaci√≥n de otros recursos se establece de la siguiente forma azurerm_resource_group.rg.name.</p>

<p>Contenido archivo main.tf:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Definici√≥n provider azurerm (Azure) y versi√≥n

terraform {
  required_providers {
    azurerm = {
      source = "hashicorp/azurerm"
      version = "3.13.0"
    }
  }
}

provider "azurerm" {
  features {}
  subscription_id = "c9f11e84-e410-46cd-82xe-xxxxxxxxxxxx"
  client_id = "62p71c17-03q2-4234-9795-xxxxxxxxxxxx"
  client_secret = "rvFpTmn_3KCOtZv.jzoK9Ox3H-xxxxxxxx"
  tenant_id = "899789xd-202f-44b4-9583-xxxxxxxxxxxx"
}

# Creaci√≥n de grupo de recursos

resource "azurerm_resource_group" "rg" {
    name = "lab_0001"
    location = var.location

    tags = {
        environment = "lab_0001"
    }
}

# Creaci√≥n de cuenta de almacenamiento

resource "azurerm_storage_account" "stAccount" {
    name = "salab0001"
    resource_group_name = azurerm_resource_group.rg.name
    location = azurerm_resource_group.rg.location
    account_tier = "Standard"
    account_replication_type = "LRS"

    tags = {
        environment = "lab_0001"
    }

}
</code></pre></div></div>

<h3 id="configuraci√≥n-del-archivo-networktf">Configuraci√≥n del archivo network.tf</h3>

<ul>
  <li>Definimos una vnet: 10.0.0.0/16</li>
  <li>Definimos una subnet: 10.0.1.0/24</li>
  <li>La subnet debe estar contenida dentro de la vnet.</li>
  <li>La NIC de todas las VMs deben estar contenidas dentro del mismo espacio de direcciones de la subnet.</li>
  <li>Asignamos un IP privada est√°tica a las VMs.</li>
  <li>Creamos una IP p√∫blica din√°mica para poder acceder desde fuera de Azure.</li>
</ul>

<p>La asignaci√≥n de una IP p√∫blica est√°tica incrementa el coste de este recurso, sin embargo, la asignaci√≥n de una IP privada est√°tica es gratuita. Al configurar la IP p√∫blica din√°mica, con el encendido y apagado de las VMs la direcci√≥n puede cambiar. En la creaci√≥n de los workers en el nombre del recurso se establece -${var.workers[count.index]} para que autom√°ticamente coja del fichero vars.tf de la variable workers los nombres definidos en default. Para que eso funcione se declara tambi√©n en el recurso a crear count = length(var.workers). Como a la VM master le hemos dado la IP 10.0.1.10, para que los workers se asignen autom√°ticamente la primera IP privada libre a partir de las 10.0.1.11 para que no se duplique la IP del master, aplicamos la siguiente configuraci√≥n private_ip_address = ‚Äú10.0.1.${count.index + 11}‚Äù.</p>

<p>Contenido de archivo network.tf:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Creaci√≥n de red virtual

resource "azurerm_virtual_network" "myNet" {
    name = "lab-0001-vnet"
    address_space = ["10.0.0.0/16"]
    location = azurerm_resource_group.rg.location
    resource_group_name = azurerm_resource_group.rg.name

    tags = {
        environment = "lab-0001"
    }
}

# Creaci√≥n de subnet

resource "azurerm_subnet" "mySubnet" {
    name = "subnet-lab-0001"
    resource_group_name = azurerm_resource_group.rg.name
    virtual_network_name = azurerm_virtual_network.myNet.name
    address_prefixes = ["10.0.1.0/24"]
}

# Creaci√≥n de interfaz de red para VM master

resource "azurerm_network_interface" "nicmaster" {
    name = "nic-master"
    location = azurerm_resource_group.rg.location
    resource_group_name = azurerm_resource_group.rg.name

      ip_configuration {
      name = "ipconf-master"
      subnet_id = azurerm_subnet.mySubnet.id
      private_ip_address_allocation = "Static"
      private_ip_address = "10.0.1.10"
      public_ip_address_id = azurerm_public_ip.myPublicIpMaster.id
}

      tags = {
          environment = "lab-0001"
      }
}

# Creaci√≥n de interfaces de red para VMs worker01 y worker02

resource "azurerm_network_interface" "nicworkers" {
    name = "nic-${var.workers[count.index]}"
    count = length(var.workers)
    location = azurerm_resource_group.rg.location
    resource_group_name = azurerm_resource_group.rg.name

      ip_configuration {
      name = "ipconf-${var.workers[count.index]}"
      subnet_id = azurerm_subnet.mySubnet.id
      private_ip_address_allocation = "Static"
      private_ip_address = "10.0.1.${count.index + 11}"
      public_ip_address_id = azurerm_public_ip.myPublicIpWorkers[count.index].id
}

      tags = {
          environment = "lab-0001"
      }
}

# IP p√∫blica VM master

resource "azurerm_public_ip" "myPublicIpMaster" {
    name = "publicip-master"
    location = azurerm_resource_group.rg.location
    resource_group_name = azurerm_resource_group.rg.name
    allocation_method = "Dynamic"
    sku = "Basic"

      tags = {
          environment = "lab-lab0001"
      }
}

# IP p√∫blica VMs worker01 y worker02

resource "azurerm_public_ip" "myPublicIpWorkers" {
    name = "publicip-${var.workers[count.index]}"
    count = length(var.workers)
    location = azurerm_resource_group.rg.location
    resource_group_name = azurerm_resource_group.rg.name
    allocation_method = "Dynamic"
    sku = "Basic"

      tags = {
          environment = "lab-0001"
      }
}
</code></pre></div></div>

<h3 id="configuraci√≥n-del-archivo-securitytf">Configuraci√≥n del archivo security.tf</h3>

<ul>
  <li>Creamos un grupo de seguridad de red (NSG).</li>
  <li>En el NSG definimos el tr√°fico que vamos a autorizar incluyendo reglas de seguridad. De momento solo se va a permitir la regla de entrada por SSH.</li>
  <li>Asociamos el NSG con todas las NIC de las VMs que se van a desplegar. De esta forma la regla que creamos se aplica a todas las VMs.</li>
</ul>

<p>Contenido del archivo security.tf:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Grupo de seguridad de red

resource "azurerm_network_security_group" "mySecGroup" {
    name = "nsg-k8s"
    location = azurerm_resource_group.rg.location
    resource_group_name = azurerm_resource_group.rg.name

    security_rule {
        name = "SSH"
        priority = "1001"
        direction ="Inbound"
        access = "Allow"
        protocol = "Tcp"
        source_port_range = "*"
        destination_port_range = "22"
        source_address_prefix = "*"
        destination_address_prefix = "*"
    }

    tags = {
        environment = "lab-0001"
    }
}

# Vincular grupo de seguridad de red con interfaz de red de vm master

resource "azurerm_network_interface_security_group_association" "associationmaster" {
    network_interface_id = azurerm_network_interface.nicmaster.id
    network_security_group_id = azurerm_network_security_group.mySecGroup.id
}


# Vincular grupo de seguridad de red con interfaz de red de worker01 y worker02

resource "azurerm_network_interface_security_group_association" "associationworers" {
    count = length(var.workers)
    network_interface_id = azurerm_network_interface.nicworkers[count.index].id
    network_security_group_id = azurerm_network_security_group.mySecGroup.id
}
</code></pre></div></div>

<h3 id="configuraci√≥n-del-archivo-vmtf">Configuraci√≥n del archivo vm.tf</h3>

<ul>
  <li>Definimos la creaci√≥n de la VM master.</li>
  <li>Definimos la creaci√≥n de las VMs workers.</li>
  <li>Definimos el tama√±o.</li>
  <li>Le asignamos las NICs creadas en network.tf.</li>
  <li>Indicamos el usuario administrador.</li>
  <li>Especificamos la clave p√∫blica para el usuario administrador. Para crear una clave SSH, para poder conectarnos a la VM hacemos uso del siguiente comando ssh-keygen -t rsa -b 4096. Por defecto la clave se almacena en ~/.ssh, el nombre que le hemos asignado es id_rsa_cp2_devops porque ya dispon√≠a de una clave con el nombre por defecto (id_rsa). No hemos asignado una contrase√±a a la clave para esta pr√°ctica. Una vez dispongamos de la clave SSH hay que restablecer la ruta de la misma en el fichero vm.tf.</li>
  <li>Utilizaremos el usuario especificado y la clave privada asociada a la p√∫blica para acceder a la VM.</li>
  <li>Definimos el tipo de disco y la replicaci√≥n (Standar_LRS).</li>
  <li>Cuando definamos images del Marketplace tendremos que definir plan y source_image_reference con los datos de la imagen que utilizaremos.</li>
  <li>Definimos la storage account a utilizar para almacenar informaci√≥n de troubleshooting.</li>
</ul>

<p>Para definir la imagen a desplegar del Marketplace, para ver todas las disponibles con CentOS ejecutamos el siguiente comando:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az vm image list --offer CentOS --all --output table
</code></pre></div></div>
<p>Desde la salida que obtenemos en formato tabla podemos elegir la imagen y tendremos otros datos necesarios para incluir en vm.tf como son offer, publisher, version, name, plan, sku y product. Una vez seleccionada una imagen, tendremos que aceptar los t√©rminos de uso de esta, si no, porque desde Terraform no es posible aceptar esos t√©rminos y condiciones. Para esta pr√°ctica se ha elefido la siguiente imagen:</p>

<p>name = ‚Äúcentos-8-3-free‚Äù
product = ‚Äúcentos-8-3-free‚Äù
publisher = ‚Äúcognosys‚Äù
offer = ‚Äúcentos-8-3-free‚Äù
sku = ‚Äúcentos-8-3-free‚Äù
version = ‚Äú1.2019.0810‚Äù</p>

<p>Por lo tanto, el comando a ejecutar para aceptar los t√©rminos y condiciones es:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az vm image terms accept --offer centos-8-3-free --plan 1.2019.0810 --publisher cognosys
</code></pre></div></div>
<p>Contenido del archivo vm.tf:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Creaci√≥n de m√°quina master

resource "azurerm_linux_virtual_machine" "vmmaster" {
    name = "master"
    resource_group_name = azurerm_resource_group.rg.name
    location = azurerm_resource_group.rg.location
    size = var.vm_size_master
    admin_username = "rafadmin"
    network_interface_ids = [ azurerm_network_interface.nicmaster.id ]
    disable_password_authentication = true
    admin_ssh_key {
        username = "rafadmin"
        public_key = file ("~/.ssh/id_rsa_cp2_devops.pub")
    }


    os_disk {
        caching = "ReadWrite"
        storage_account_type = "Standard_LRS"
    }

    plan {
        name = "centos-8-3-free"
        product = "centos-8-3-free"
        publisher = "cognosys"
    }
  
      source_image_reference {
        publisher = "cognosys"
        offer = "centos-8-3-free"
        sku = "centos-8-3-free"
        version = "1.2019.0810"
    }

    boot_diagnostics {
        storage_account_uri = azurerm_storage_account.stAccount.primary_blob_endpoint
    }

    tags = {
        environment = "lab-0001"
    }

}


# Creaci√≥n de m√°quinas virtuales worker01 y worker02

resource "azurerm_linux_virtual_machine" "vmsworkers" {
    name = "${var.workers[count.index]}"
    count = length(var.workers)
    resource_group_name = azurerm_resource_group.rg.name
    location = azurerm_resource_group.rg.location
    size = var.vm_size_workers
    admin_username = "rafadmin"
    network_interface_ids = [ azurerm_network_interface.nicworkers[count.index].id ]
    disable_password_authentication = true

    admin_ssh_key {
        username = "rafadmin"
        public_key = file ("~/.ssh/id_rsa_cp2_devops.pub")
    }

    os_disk {
        caching = "ReadWrite"
        storage_account_type = "Standard_LRS"
    }

    plan {
        name = "centos-8-3-free"
        product = "centos-8-3-free"
        publisher = "cognosys"
          }

    source_image_reference {
        publisher = "cognosys"
        offer = "centos-8-3-free"
        sku = "centos-8-3-free"
        version = "1.2019.0810"
    }

    boot_diagnostics {
        storage_account_uri = azurerm_storage_account.stAccount.primary_blob_endpoint
    }

    tags = {
        environment = "lab-0001"
    }
}
</code></pre></div></div>

<h1 id="despliegue-automatizado-de-la-infraestructura-con-terraform">Despliegue automatizado de la infraestructura con Terraform</h1>

<p>Una vez configuramos todos los archivos .tf es hora de preparar, planear y aplicar.</p>

<ol>
  <li>Preparar la infraestructura</li>
</ol>

<p>La primera vez que se va a realizar un despliegue o tras aplicar cambios en los archivos .tf debemos inicializar la configuraci√≥n de Terraform, para ello ejecutamos el siguiente comando:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform init
</code></pre></div></div>
<p>Si todo ha ido correctamente debemos obtener el siguiente resultado:</p>

<p><img src="/images/terraform-init.png" alt="Ejecuci√≥n de 'terraform init'" /></p>

<ol>
  <li>Realizar un plan</li>
</ol>

<p>El segundo paso es realizar un terraform plan. Esta funcionalidad nos permite ver las acciones que se van a realizar para lograr el estado deseado, para ello ejecutamos el siguiente comando:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform plan
</code></pre></div></div>
<p>Debemos obtener una salida sin errores, donde nos detalle que recursos vamos a√±adir, actualizar o destruir.</p>

<p>Si observamos toda la salida, nos vendr√° marcada con un + sobre todos los reucrsos que se van a crear. Esto puede variar cuando realicemos un cambio a futuro, si un recurso se va a destruir viene indicado con un -, si se va actualizar con un ~. De esta forma nos permite ver las acciones que se van a llevar a cabo antes del despligue.</p>

<p><img src="/images/terraform-plan.png" alt="Ejecuci√≥n de 'terraform plan'" /></p>

<ol>
  <li>Aplicar el despliegue</li>
</ol>

<p>Por √∫ltimo, para aplicar el despliegue tendremos que ejecutar el comando</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform apply
</code></pre></div></div>
<p>Este comando ejecutar√° primero un plan, que posteriormente tendremos que aceptar con un ‚Äòyes‚Äô o ‚Äòno‚Äô para realizar o no el despliegue.</p>

<p><img src="/images/terraform-apply.png" alt="Ejecuci√≥n de 'terraform apply'" /></p>

<p>Durante el despliegue podemos ver la salida de los recursos que se est√°n creado. Tras la finalizaci√≥n podremos observar que recursos se han agregado, actualizado o destruido. En este caso solo se deben crear recursos.</p>

<p><img src="/images/terraform-apply-output.png" alt="Salida obtenida tras aplicar 'terraform apply'" /></p>

<p>Terraform almacena el estado de la infraestructura en un archivo llamado terraform.state. De esta forma Terraform detecta cuando se producen cambios en la infraestructura, compara los archivos .tf con el .state. Si se agregan nuevos recursos a los ficheros .tf detectar√° que no existen en .state y los crear√°, si se elimina alg√∫n recursos de los archivos .tf detectar√° que en .state est√° y los eliminar√° y por √∫ltimo si se realiza una acutalizaci√≥n de un recurso en el archivo .tf por ejemplo cambiar una IP de est√°tica a din√°mica, Terraform detectar√° que en el .state existe la IP como est√°tica y aplicar√° el cambio a din√°mica.</p>

<p>Tras realizar el despliegue podemos comprobar en Azure los recursos que se han creado:</p>

<p><img src="/images/grupo-de-recursos-lab0001.png" alt="Creaci√≥n grupo de recursos lab_0001" /></p>

<p><img src="/images/recursos-lab0001.png" alt="Recursos lab_0001" /></p>

<p><img src="/images/vms-lab0001.png" alt="M√°quinas virtuales lab_0001" /></p>

<p>Para destruir o eliminar la infraestructura creada tenemos que ejecutar el siguiente comando y confirmar con ‚Äòyes‚Äô:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform destroy
</code></pre></div></div>
<p><img src="/images/terraform-destroy.png" alt="Ejecuci√≥n comando 'terraform destroy'" /></p>

<p>Tras confirmar la eliminaci√≥n obtendremos la siguiente salida:</p>

<p><img src="/images/destroy-output.png" alt="Salida comando 'terraform destroy'" /></p>
:ET