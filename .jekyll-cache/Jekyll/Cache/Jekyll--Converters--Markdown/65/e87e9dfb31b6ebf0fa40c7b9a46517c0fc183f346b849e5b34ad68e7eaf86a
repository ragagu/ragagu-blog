I"≥3<p>En el siguiente lab voy a instalar y configurar <strong>Terraform</strong> en una m√°quina Windows 11 con <strong>WSL</strong>, haciendo uso de la distribuci√≥n <strong>Ubuntu 22.04 LTS</strong>, pero, el despliegue se puede llevar a cabo desde cualquier m√°quina con Linux. Posteriormente voy a desplegar la siguiente infraestructura en <strong>Azure</strong>:</p>

<ul>
  <li>Un grupo de recursos.</li>
  <li>Una m√°quina virtual con 2vCPU, 4GB de RAM y 30GB HDD con una imagen CentOS (master).</li>
  <li>Dos m√°quinas virtuales con 1vCPU, 2GB de RAM y 30GB HDD con una imagen CentOS (workers).</li>
  <li>Tres IPs p√∫blicas din√°micas.</li>
  <li>Una red virtual.</li>
  <li>Un grupo de seguridad de red (NSG).</li>
</ul>

<h1 id="preparaci√≥n-del-entorno-para-automatizar-el-despliegue">Preparaci√≥n del entorno para automatizar el despliegue</h1>

<p>En primer lugar, tenemos que instalar Terraform en la m√°quina Linux donde se va automatizar el despliegue. De forma predeterminada, Terraform no est√° incluido en el repositorio est√°ndar de Ubuntu. Debemos instalar los siguientes paquetes:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt-get install curl gnupg2 software-properties-common -y
</code></pre></div></div>
<p>Posteriormente agregamos la clave GPG Terraform y el respositorio:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo curl -fsSL https://apt.releases.hashicorp.com/gpg | apt-key add -
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt-add-repository "deb [arch=$(dpkg --print-architecture)] https://apt.releases.hashicorp.com 
$(lsb_release -cs) main"
</code></pre></div></div>
<p>Por √∫ltimo instalamos Terraform:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt-get install terraform -y
</code></pre></div></div>
<p>Para verificar la instalaci√≥n de Terraform ejecutamos:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform -v
</code></pre></div></div>

<p>En segundo lugar, tenemos que crear un service principal para conectar el provider azurerm de Terraform con nuestro tenant de Azure. Hacemos uso de Azure CLI. Instalamos Azure CLI mediante el siguiente comando:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
</code></pre></div></div>
<p>Para crear un service principal tenemos que conectarnos al tenant de Azure con</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> az login
</code></pre></div></div>

<p>Con el siguiente comando creamos el service principal:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az ad sp create-for-rbac --role="Contributor"
</code></pre></div></div>
<p>Obtenemos una salida similar a la siguiente, donde obtendremos el appid, nombre, password y tenant id:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>In a future release, --scopes argument will become required for creating a role assignment. Please explicitly 
specify --scopes.
Creating 'Contributor' role assignment under scope '/subscriptions/c9f11e84-d381-46cd-82be4f39add24081'
The output includes credentials that you must protect. Be sure that you do not include these credentials in 
your code or check the credentials into your source control. For more information, see 
https://aka.ms/azadsp-cli
{
 "appId": "62p71c17-03q2-4234-9795-xxxxxxxxxxxx",
 "displayName": "azure-cli-2022-03-06-14-47-39",
 "password": "rvFpTmn_3KCOtZv.jzoK9Ox3H-xxxxxxxx",
 "tenant": "899789xd-202f-44b4-9583-xxxxxxxxxxxx"
}
</code></pre></div></div>
<h2 id="creaci√≥n-de-estructura-de-directorio-y-archivos-terraform">Creaci√≥n de estructura de directorio y archivos Terraform</h2>

<p>Clonamos el siguiente repositorio en la m√°quina donde vamos automatizar el despliegue de la infraestructura con Terrafrom <code class="language-plaintext highlighter-rouge">https://github.com/ragagu/laboratorios</code></p>

<blockquote>
  <p>Para instalar Git ejecuta el comando <code class="language-plaintext highlighter-rouge">sudo apt install git</code></p>
</blockquote>

<p>Accedemos al directorio cp2devopsunir/terraform y vemos la estructura de archivos siguientes:</p>

<ul>
  <li>main.tf</li>
  <li>network.tf</li>
  <li>security.tf</li>
  <li>vars.tf</li>
  <li>vm.tf</li>
</ul>

<h3 id="configuraci√≥n-de-archivo-varstf">Configuraci√≥n de archivo vars.tf</h3>

<ul>
  <li>En este fichero declaramos todas las variables.</li>
  <li>Declaramos la localizaci√≥n para ubicar en la regi√≥n donde se van a desplegar los recursos. Para ver las regiones disponibles: az account list-locations</li>
  <li>Declaramos la variable para el nombre de la talla de la m√°quina virtual m√°ster. Para ver las tallas disponibles en la regi√≥n seleccionada: az vm list-sizes ‚Äìlocation westeurope</li>
  <li>Declaramos la variable para el nombre de la talla de las m√°quinas workers. Como las dos VM workers van a ser iguales, solamente va a cambiar el nombre, aplicamos el tipo lists(string) y los nombres de ambas VM en default. En los archivos main.tf, network.tf, security.tf y vm.tf haremos uso de count para configurar estas dos VMs.</li>
</ul>

<p>Nota: si est√°s haciendo uso de una suscripci√≥n de educaci√≥n o pruebas est√°n limitadas a un m√°ximo de 4 Cores, este l√≠mite se puede ampliar, pero no es posible hacerlo con este tipo de suscripci√≥n, la soluci√≥n es pasar a una suscripci√≥n de pago por uso.</p>

<p>Contenido archivo vars.tf:</p>

<h3 id="configuraci√≥n-de-archivo-maintf">Configuraci√≥n de archivo main.tf</h3>

<ul>
  <li>Configuramos el provider del que har√° uso Terraform, en este caso azurerm.</li>
  <li>Incluimos la informaci√≥n del service principal creado en el punto 3.2.</li>
  <li>Creamos y configuramos un grupo de recursos.</li>
  <li>Creamos y configuramos una cuenta de almacenamiento.</li>
</ul>

<p>Nota: como podemos ver para la configuraci√≥n location se hace llamamiento a la variable var.location, de esta forma se configurar√≠a West Europe, tal y como est√° definido en vars.tf. Como podemos observar en todos los recursos hay que indicar el nombre del grupo de recursos donde se va a desplegar, como el nombre ya est√° definido en la creaci√≥n del grupo de recursos el llamamiento al nombre de este en la creaci√≥n de otros recursos se establece de la siguiente forma azurerm_resource_group.rg.name.</p>

<p>Contenido archivo main.tf</p>

<h3 id="configuraci√≥n-del-archivo-networktf">Configuraci√≥n del archivo network.tf</h3>

<ul>
  <li>Definimos una vnet: 10.0.0.0/16</li>
  <li>Definimos una subnet: 10.0.1.0/24</li>
  <li>La subnet debe estar contenida dentro de la vnet.</li>
  <li>La NIC de todas las VMs deben estar contenidas dentro del mismo espacio de direcciones de la subnet.</li>
  <li>Asignamos un IP privada est√°tica a las VMs.</li>
  <li>Creamos una IP p√∫blica din√°mica para poder acceder desde fuera de Azure.</li>
</ul>

<p>Nota: la asignaci√≥n de una IP p√∫blica est√°tica incrementa el coste de este recurso, sin embargo, la asignaci√≥n de una IP privada est√°tica es gratuita. Al configurar la IP p√∫blica din√°mica, con el encendido y apagado de las VMs la direcci√≥n puede cambiar. En la creaci√≥n de los workers en el nombre del recurso se establece -${var.workers[count.index]} para que autom√°ticamente coja del fichero vars.tf de la variable workers los nombres definidos en default. Para que eso funcione se declara tambi√©n en el recurso a crear count = length(var.workers). Como a la VM master le hemos dado la IP 10.0.1.10, para que los workers se asignen autom√°ticamente la primera IP privada libre a partir de las 10.0.1.11 para que no se duplique la IP del master, aplicamos la siguiente configuraci√≥n private_ip_address = ‚Äú10.0.1.${count.index + 11}‚Äù.</p>

<p>Contenido de archivo network.tf</p>

<h3 id="configuraci√≥n-del-archivo-securitytf">Configuraci√≥n del archivo security.tf</h3>

<ul>
  <li>Creamos un grupo de seguridad de red (NSG).</li>
  <li>En el NSG definimos el tr√°fico que vamos a autorizar incluyendo reglas de seguridad. De momento solo se va a permitir la regla de entrada por SSH.</li>
  <li>Asociamos el NSG con todas las NIC de las VMs que se van a desplegar. De esta forma la regla que creamos se aplica a todas las VMs.</li>
</ul>

<p>Contenido del archivo security.tf</p>

<h3 id="configuraci√≥n-del-archivo-vmtf">Configuraci√≥n del archivo vm.tf</h3>

<ul>
  <li>Definimos la creaci√≥n de la VM master.</li>
  <li>Definimos la creaci√≥n de las VMs workers.</li>
  <li>Definimos el tama√±o.</li>
  <li>Le asignamos las NICs creadas en network.tf.</li>
  <li>Indicamos el usuario administrador.</li>
  <li>Especificamos la clave p√∫blica para el usuario administrador. Para crear una clave SSH, para poder conectarnos a la VM hacemos uso del siguiente comando ssh-keygen -t rsa -b 4096. Por defecto la clave se almacena en ~/.ssh, el nombre que le hemos asignado es id_rsa_cp2_devops porque ya dispon√≠a de una clave con el nombre por defecto (id_rsa). No hemos asignado una contrase√±a a la clave para esta pr√°ctica. Una vez dispongamos de la clave SSH hay que restablecer la ruta de la misma en el fichero vm.tf.</li>
  <li>Utilizaremos el usuario especificado y la clave privada asociada a la p√∫blica para acceder a la VM.</li>
  <li>Definimos el tipo de disco y la replicaci√≥n (Standar_LRS).</li>
  <li>Cuando definamos images del Marketplace tendremos que definir plan y source_image_reference con los datos de la imagen que utilizaremos.</li>
  <li>Definimos la storage account a utilizar para almacenar informaci√≥n de troubleshooting.</li>
</ul>

<p>Nota: para definir la imagen a desplegar del Marketplace, para ver todas las disponibles con CentOS ejecutamos el siguiente comando az vm image list ‚Äìoffer CentOS ‚Äìall ‚Äìoutput table desde la salida que nos da en formato tabla podemos elegir la imagen y tendremos otros datos necesarios para incluir en vm.tf como son offer, publisher, version, name, plan, sku y product. Una vez seleccionada una imagen, tendremos que aceptar los t√©rminos de uso de esta, si no, porque desde Terraform no es posible aceptar esos t√©rminos y condiciones. Para esta pr√°ctica se ha elefido la siguiente imagen:</p>

<p>name = ‚Äúcentos-8-3-free‚Äù
product = ‚Äúcentos-8-3-free‚Äù
publisher = ‚Äúcognosys‚Äù
offer = ‚Äúcentos-8-3-free‚Äù
sku = ‚Äúcentos-8-3-free‚Äù
version = ‚Äú1.2019.0810‚Äù</p>

<p>Por lo tanto, el comando a ejecutar para aceptar los t√©rminos y condiciones es:</p>

<p>az vm image terms accept ‚Äìoffer centos-8-3-free ‚Äìpublisher cognosys ‚Äìplan 1.2019.0810</p>

<p>Contenido del archivo vm.tf</p>

<h1 id="despliegue-automaticado-de-la-infraestructura-con-terraform">Despliegue automaticado de la infraestructura con Terraform</h1>

<p>Una vez configuramos todos los archivos .tf es hora de preparar, planear y aplicar.</p>

<ol>
  <li>Preparar la infraestructura</li>
</ol>

<p>La primera vez que se va a realizar un despliegue o tras aplicar cambios en los archivos .tf debemos inicializar la configuraci√≥n de Terraform, para ello ejecutamos el siguiente comando:</p>

<p>terraform init</p>

<p>Si todo ha ido correctamente debemos obtener el siguiente resultado:</p>

<ol>
  <li>Realizar un plan</li>
</ol>

<p>El segundo paso es realizar un terraform plan. Esta funcionalidad nos permite ver las acciones que se van a realizar para lograr el estado deseado, para ello ejecutamos el siguiente comando:</p>

<p>terraform plan</p>

<p>Debemos obtener una salida sin errores, donde nos detalle que recursos vamos a√±adir, actualizar o destruir.</p>

<p>Si observamos toda la salida, nos vendr√° marcada con un + sobre todos los reucrsos que se van a crear. Esto puede variar cuando realicemos un cambio a futuro, si un recurso se va a destruir viene indicado con un -, si se va actualizar con un ~. De esta forma nos permite ver las acciones que se van a llevar a cabo antes del despligue.</p>

<ol>
  <li>Aplicar el despliegue</li>
</ol>

<p>Por √∫ltimo, tendremos que ejecutar el comando terraform apply. Este comando ejecutar√° primero un plan como en el paso 2, que posteriormente tendremos que aceptar con un yes para que se realice el despliegue.</p>

<p>Nota: Terraform almacena el estado de la infraestructura en un archivo llamado terraform.state. De esta forma Terraform detecta cuando se producen cambios en la infraestructura, comapra los archivos .tf con el .state. Si se agregan nuevos recursos a los ficheros .tf detectar√° que no existen en .state y los crear√°, si se elimina alg√∫n recursos de los archivos .tf detectar√° que en .state est√° y los eliminar√° y por √∫ltimo si se realiza una acutalizaci√≥n de un recurso en el archivo .tf por ejemplo cambiar una IP de est√°tica a din√°mica, Terraform detectar√° que en el .state existe la IP como est√°tica y aplicar√° el cambio a din√°mica.</p>
:ET